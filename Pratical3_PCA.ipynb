{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict via the user-specific median.\n",
    "# If the user has no data, use the global median.\n",
    "\n",
    "train_file = 'train.csv'\n",
    "test_file  = 'test.csv'\n",
    "soln_file  = 'user_median.csv'\n",
    "prof_file = 'profiles.csv'\n",
    "art_file = 'artists.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "train_data = {}\n",
    "with open(train_file, 'r') as train_fh:\n",
    "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
    "    next(train_csv, None)\n",
    "    for row in train_csv:\n",
    "        user   = row[0]\n",
    "        artist = row[1]\n",
    "        plays  = row[2]\n",
    "    \n",
    "        if not user in train_data:\n",
    "            train_data[user] = {}\n",
    "        \n",
    "        train_data[user][artist] = int(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the user profile data into dictionaries\n",
    "prof_data = {}\n",
    "prof_sex = {}\n",
    "prof_age = {}\n",
    "prof_loc = {}\n",
    "with open(prof_file, 'r') as prof_fh:\n",
    "    prof_csv = csv.reader(prof_fh, delimiter=',', quotechar='\"')\n",
    "    next(prof_csv, None)\n",
    "    for row in prof_csv:\n",
    "        user   = row[0]\n",
    "        sex = row[1]\n",
    "        age = row[2]\n",
    "        loc = row[3]\n",
    "        # add other\n",
    "    \n",
    "        if not user in prof_data:\n",
    "            prof_data[user] = {}\n",
    "        \n",
    "        #train_data[user][artist] = int(plays)\n",
    "        prof_data[user] = [sex, age, loc]\n",
    "        # alternatively: store in separate dictionaries?\n",
    "        prof_sex[user] = sex\n",
    "        prof_age[user] = age\n",
    "        prof_loc[user] = loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_file)\n",
    "df_test= pd.read_csv(test_file) # etc if want to handle as pandas df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233286L,)\n",
      "fa40b43298ba3f8aa52e8e8863faf2e2171e0b5d\n"
     ]
    }
   ],
   "source": [
    "df_prof = pd.read_csv(prof_file)\n",
    "prof_vals = df_prof.values\n",
    "all_ids = prof_vals.T[:][0]\n",
    "print all_ids.shape\n",
    "print all_ids[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000L,)\n",
      "03098741-08b3-4dd7-b3f6-1b0bfa2c879c\n"
     ]
    }
   ],
   "source": [
    "df_arts = pd.read_csv(art_file)\n",
    "art_vals = df_arts.values\n",
    "all_arts = art_vals.T[:][0]\n",
    "print all_arts.shape\n",
    "print all_arts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233286L, 2000L)\n"
     ]
    }
   ],
   "source": [
    "# now: PCA analysis\n",
    "# want to construct matrix where row is one user, columns are artists, entries are listeners\n",
    "# so, matrix will be 233286 x 2000\n",
    "\n",
    "s1 = all_ids.shape[0]\n",
    "s2 = all_arts.shape[0]\n",
    "\n",
    "data_mat = np.ndarray([s1, s2])\n",
    "print data_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time:  -3007.62899995\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# instead: populate using dictionaries -> should be much quicker? no lookups\n",
    "\n",
    "t = time.time()\n",
    "# data_mat = np.ndarray([s1, s2]) # this was defined above\n",
    "# for each user-artist combo\n",
    "for i in range(s1):\n",
    "    for j in range(s2):\n",
    "        usr = all_ids[i]\n",
    "        art = all_arts[j]\n",
    "        #try-catch in case no data\n",
    "        try:\n",
    "            tmp = train_data[usr][art]\n",
    "            #print i,',',j\n",
    "            #print tmp\n",
    "        except KeyError: # if no corresponding key\n",
    "            tmp = 0\n",
    "        # populate matrix\n",
    "        data_mat[i][j]=tmp\n",
    "print 'elapsed time: ', t - time.time()\n",
    "print 'All done!'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print all_ids[0]\n",
    "print all_arts[0]\n",
    "\n",
    "#print train_data[all_ids[0]]\n",
    "art = 'cd8c5019-5d75-4d5c-bc28-e1e26a7dd5c8'\n",
    "# find artist id index\n",
    "tmp = np.equal(art,all_arts)\n",
    "j = np.nonzero(tmp)[0][0]\n",
    "print j\n",
    "art2 = all_arts[j]\n",
    "print art2\n",
    "try:\n",
    "    print train_data[all_ids[0]][all_arts[0]]\n",
    "except KeyError:\n",
    "    print 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define script for file writing\n",
    "def write_to_file(filename, data):\n",
    "    with open(filename, \"w\") as f:\n",
    "        #f.write(\"Id,Prediction\\n\")\n",
    "        for i in range(s1): # for each row\n",
    "            for j in range(s2): # for each column\n",
    "                f.write(str(data[i][j]) + \",\") # write matrix entry\n",
    "            f.write(\"\\n\") # new line after each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output matrix as a CSV file\n",
    "write_to_file(\"usr-art_mat.csv\", data_mat)\n",
    "#data_mat.tofile('usr-art_mat.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print np.sum(data_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000L, 2000L)\n"
     ]
    }
   ],
   "source": [
    "# find covariance *in* MATLAB?\n",
    "#print data_mat.shape\n",
    "Sigma = np.cov(data_mat.T)\n",
    "print Sigma.shape # should be 2k x 2k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find principal components\n",
    "L, V = np.linalg.eig(Sigma) # L holds eigenvalues, V holds eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-068699e403d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_proj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_mat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# project onto PCA axes\n",
    "data_proj = np.dot(data_mat,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -9.53363010e-06  -2.38119052e-05   1.23104825e-05 ...,  -5.33245400e-04\n",
      "    1.26778732e-03   7.81296072e-04]\n",
      " [  3.53203650e-05  -4.87148011e-05   1.12781260e-05 ...,   5.51365545e-04\n",
      "   -5.94670431e-04  -1.95761484e-04]\n",
      " [  3.02338075e-05  -2.36689274e-05   8.85349186e-06 ...,  -3.18407654e-02\n",
      "   -6.32800472e-02  -3.77361364e-02]\n",
      " ..., \n",
      " [  4.09129315e-06   7.07845112e-06   7.46890654e-06 ...,   1.60515820e-02\n",
      "    8.67354550e-04  -5.54315141e-03]\n",
      " [ -1.15388447e-06  -7.22470524e-06   5.95583753e-06 ...,  -2.42958948e-04\n",
      "   -2.98450678e-02   4.67839829e-03]\n",
      " [ -1.54816944e-05  -4.80399776e-05   2.37139089e-05 ...,   2.30401806e-03\n",
      "   -5.25807754e-04   7.29334249e-04]]\n"
     ]
    }
   ],
   "source": [
    "print V[:]\n",
    "#plt.plot(range(2000),)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alternatively? subtract mean first to get more compressed PC's\n",
    "# PC's will then capture changes relative to some average profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the global median and per-user median.\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "for user, user_data in train_data.iteritems():\n",
    "    user_plays = []\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "\n",
    "    user_medians[user] = np.median(np.array(user_plays))\n",
    "global_median = np.median(np.array(plays_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write out test solutions.\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "\n",
    "            if user in user_medians:\n",
    "                soln_csv.writerow([id, user_medians[user]])\n",
    "            else:\n",
    "                print \"User\", id, \"not in training data.\"\n",
    "                soln_csv.writerow([id, global_median])\n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
