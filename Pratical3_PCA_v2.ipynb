{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn.mixture import GMM # gaussian mixture model\n",
    "## ultimately: try LDA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict via the user-specific median.\n",
    "# If the user has no data, use the global median.\n",
    "\n",
    "train_file = 'train.csv'\n",
    "test_file  = 'test.csv'\n",
    "soln_file  = 'user_median.csv'\n",
    "prof_file = 'profiles.csv'\n",
    "art_file = 'artists.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "\n",
    "# new: partition into training and validation set\n",
    "# if we want to use all data for training? just set rMax to > 5M\n",
    "rMax = 6000000 # use first 3M to populate training matrix; after that, test\n",
    "r = 0\n",
    "idx = 1\n",
    "\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "with open(train_file, 'r') as train_fh:\n",
    "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
    "    next(train_csv, None)\n",
    "\n",
    "    for row in train_csv:\n",
    "        user   = row[0]\n",
    "        artist = row[1]\n",
    "        plays  = row[2]\n",
    "        \n",
    "        if r<rMax: # then populate training data\n",
    "            if not user in train_data:\n",
    "                train_data[user] = {}\n",
    "        \n",
    "            train_data[user][artist] = int(plays)\n",
    "            r = r+1\n",
    "        else: # else populate validation set\n",
    "            test_data[idx] = [user, artist, plays] # with valid set: now how extra entry for real # of plays\n",
    "            idx = idx+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nTest = idx-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternatively: Load the 'real' test data.\n",
    "test_data = {}\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "    for row in test_csv:\n",
    "        id   = int(row[0])\n",
    "        user = row[1]\n",
    "        artist  = row[2]\n",
    "    \n",
    "        #if not user in train_data:\n",
    "        #    train_data[user] = {}\n",
    "        \n",
    "        test_data[id] = [user, artist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'10'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6106cddcb58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mprof_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mart_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '10'"
     ]
    }
   ],
   "source": [
    "nTest = int(id)\n",
    "tmp = test_data[str(10)]\n",
    "print prof_idx[tmp[0]]\n",
    "print art_idx[tmp[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the user profile data into dictionaries\n",
    "prof_data = {}\n",
    "prof_sex = {}\n",
    "prof_age = {}\n",
    "prof_loc = {}\n",
    "prof_idx = {}\n",
    "idx = 0\n",
    "with open(prof_file, 'r') as prof_fh:\n",
    "    prof_csv = csv.reader(prof_fh, delimiter=',', quotechar='\"')\n",
    "    next(prof_csv, None)\n",
    "    for row in prof_csv:\n",
    "        user   = row[0]\n",
    "        sex = row[1]\n",
    "        age = row[2]\n",
    "        loc = row[3]\n",
    "        # add other\n",
    "    \n",
    "        if not user in prof_data:\n",
    "            prof_data[user] = {}\n",
    "        \n",
    "        #train_data[user][artist] = int(plays)\n",
    "        prof_data[user] = [sex, age, loc]\n",
    "        # alternatively: store in separate dictionaries?\n",
    "        prof_sex[user] = sex\n",
    "        prof_age[user] = age\n",
    "        prof_loc[user] = loc\n",
    "        prof_idx[user] = idx\n",
    "        idx = idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# also, for later: create artist dictionary\n",
    "# saves time from using find commands for writing data\n",
    "art_data = {}\n",
    "art_name = {}\n",
    "art_idx = {}\n",
    "idx = 0\n",
    "with open(art_file, 'r') as art_fh:\n",
    "    art_csv = csv.reader(art_fh, delimiter=',', quotechar='\"')\n",
    "    next(art_csv, None)\n",
    "    for row in art_csv:\n",
    "        artist   = row[0]\n",
    "        name = row[1]\n",
    "        \n",
    "        #train_data[user][artist] = int(plays)\n",
    "        art_data[artist] = [name, idx]\n",
    "        # alternatively: store in separate dictionaries?\n",
    "        art_name[artist] = name\n",
    "        art_idx[artist] = idx\n",
    "        idx = idx+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_file)\n",
    "df_test= pd.read_csv(test_file) # etc if want to handle as pandas df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233286,)\n",
      "fa40b43298ba3f8aa52e8e8863faf2e2171e0b5d\n"
     ]
    }
   ],
   "source": [
    "df_prof = pd.read_csv(prof_file)\n",
    "prof_vals = df_prof.values\n",
    "all_ids = prof_vals.T[:][0]\n",
    "print all_ids.shape\n",
    "print all_ids[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "03098741-08b3-4dd7-b3f6-1b0bfa2c879c\n"
     ]
    }
   ],
   "source": [
    "df_arts = pd.read_csv(art_file)\n",
    "art_vals = df_arts.values\n",
    "all_arts = art_vals.T[:][0]\n",
    "print all_arts.shape\n",
    "print all_arts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233286, 2000)\n"
     ]
    }
   ],
   "source": [
    "# now: PCA analysis\n",
    "# want to construct matrix where row is one user, columns are artists, entries are listens\n",
    "# so, matrix will be 233286 x 2000\n",
    "\n",
    "s1 = all_ids.shape[0]\n",
    "s2 = all_arts.shape[0]\n",
    "\n",
    "data_mat = np.ndarray([s1, s2])\n",
    "print data_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time:  829.774206877\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# instead: populate using dictionaries -> should be much quicker? no lookups\n",
    "\n",
    "t = time.time()\n",
    "# data_mat = np.ndarray([s1, s2]) # this was defined above\n",
    "# for each user-artist combo\n",
    "for i in range(s1):\n",
    "    for j in range(s2):\n",
    "        usr = all_ids[i]\n",
    "        art = all_arts[j]\n",
    "        #try-catch in case no data\n",
    "        try:\n",
    "            tmp = train_data[usr][art]\n",
    "            #print i,',',j\n",
    "            #print tmp\n",
    "        except KeyError: # if no corresponding key\n",
    "            tmp = 0\n",
    "        # populate matrix\n",
    "        data_mat[i][j]=tmp\n",
    "print 'elapsed time: ', time.time()-t\n",
    "print 'All done!'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233286, 2000)\n"
     ]
    }
   ],
   "source": [
    "print data_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define script for file writing\n",
    "def write_to_file(filename, data):\n",
    "    with open(filename, \"w\") as f:\n",
    "        #f.write(\"Id,Prediction\\n\")\n",
    "        for i in range(s1): # for each row\n",
    "            for j in range(s2): # for each column\n",
    "                f.write(str(data[i][j]) + \",\") # write matrix entry\n",
    "            f.write(\"\\n\") # new line after each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## output matrix as a CSV file\n",
    "write_to_file(\"usr-art_mat.csv\", data_mat)\n",
    "#data_mat.tofile('usr-art_mat.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear space in case we've been going back and forth?\n",
    "# del L, V, data_proj, Sigma\n",
    "del km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278.563163996\n"
     ]
    }
   ],
   "source": [
    "# standardize data? before or after finding principal components?\n",
    "# del data_sub # for memory conservation\n",
    "t = time.time()\n",
    "std_scale = preprocessing.StandardScaler().fit(data_mat)\n",
    "data_scaled = std_scale.transform(data_mat)\n",
    "print time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2000)\n"
     ]
    }
   ],
   "source": [
    "# and use this to find covariance, and thus principal components?\n",
    "# Sigma = np.cov(data_mat) # PCA on raw data\n",
    "# Sigma = np.cov(data_sub.T) # PCA on mean-subtracted data\n",
    "Sigma = np.cov(data_scaled.T)\n",
    "print Sigma.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find principal components\n",
    "L, V = np.linalg.eig(Sigma) # L holds eigenvalues, V holds eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233286, 2000)\n"
     ]
    }
   ],
   "source": [
    "# project onto PCA axes\n",
    "data_proj = np.dot(data_mat,V)\n",
    "print data_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for u in range(10): # plot first 10 users in PCA basis?\n",
    "    plt.plot(data_proj[u])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n",
      "training time =  51.0127370358  seconds\n"
     ]
    }
   ],
   "source": [
    "# simplest clustering: KMeans\n",
    "nPCs = 10 # how many PCs to include in fit\n",
    "K = 15 # how many cluster centers to fit\n",
    "\n",
    "# if validating: set aside users to compare predictions to?\n",
    "nValid = 10000 # set aside 10k\n",
    "\n",
    "data_tofit = data_proj.T[:nPCs].T\n",
    "data_tofit = data_tofit[nValid:] # leave out validation set\n",
    "\n",
    "\n",
    "# construct classifier\n",
    "km = KMeans(n_clusters=K)\n",
    "# train?\n",
    "t = time.time()\n",
    "km.fit(data_proj.T[:nPCs].T) # use all users\n",
    "#km.fit(data_tofit) # if validating, fit a subset\n",
    "print 'Finished training!'\n",
    "print 'training time = ', time.time()-t,' seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233286, 10)\n",
      "[ 1  5  1 13  1  5  1  1  1  1  5  3  1  1  1  1  5  1  5  1  1 11  1  1  5\n",
      "  1 11  1  1  1  1  1  1  1 13  1  5  1  1 10  1  1 10  5  1  1  1  1  1  1\n",
      "  5  5  1  1  1  4  1  1  1  1  1  1  5  1 11  1  1  1  1  1  1  1  5  1  1\n",
      "  1  1  1  1 13  1  1  1  1  1  2  1  1  1  1  1  0  5  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# get predictions?\n",
    "# first, try on a test sample:\n",
    "\n",
    "tmp = data_proj.T[:nPCs].T\n",
    "# tmp = tmp[:nValid] # in not validating, want to predict all clusters\n",
    "print tmp.shape\n",
    "\n",
    "# get cluster centers\n",
    "mus = km.cluster_centers_\n",
    "\n",
    "# returns cluster center\n",
    "predKs = km.predict(tmp)\n",
    "print predKs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check if at all reasonable?\n",
    "plt.plot(mus[0])\n",
    "plt.plot(tmp[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(641L,)\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# debugging to get cluster median sorting correct\n",
    "tmp = np.equal(predKs, 4)\n",
    "idx = np.nonzero(tmp)[0]\n",
    "#print idx\n",
    "k_ids = all_ids[idx]\n",
    "print k_ids.shape\n",
    "print K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find medians *of each artist* within each cluster\n",
    "clusterMem = {} # dictionary of members for each user\n",
    "for k in range(K): # for each cluster\n",
    "    tmp = np.equal(predKs,k)\n",
    "    k_idx = np.nonzero(tmp)[0] # numeric indices of all users assigned to that cluster\n",
    "    k_ids = all_ids[k_idx] # correspondeng alphanumeric user ids\n",
    "    clusterMem[k] = k_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34948L,)\n",
      "(771L,)\n"
     ]
    }
   ],
   "source": [
    "print clusterMem[0].shape\n",
    "print clusterMem[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de29005de66c93b31a34991b0c72d9f70b9fc313 c0b2500e-0cef-4130-869d-732b23ed9df5\n",
      "[9334, 570, 788, 173, 907, 10182, 3875, 192, 4133, 1183, 6412, 588, 638, 10941, 9409, 22228, 770, 7769, 329, 744, 360, 3062, 2209, 220, 279, 1071, 829, 1306, 1776, 1639, 1193, 269, 658, 904, 327, 2758, 32391, 901, 696, 7868, 4698, 11540, 677, 162, 867, 265, 2968, 488, 11012, 410, 3178, 4049, 457, 2612, 106, 879, 12312, 2047, 636, 2092, 2179, 6794, 140, 1570, 3610, 12580, 7124, 189, 1033, 3905, 1880, 2240, 541, 392, 100, 448, 5186, 2640, 17044, 749, 996, 628, 572, 432, 10299, 6301, 153, 1409, 647, 2772, 544, 1882, 511, 13433, 767, 676, 652, 153, 3167, 170, 184, 1057, 7559, 4064, 1805, 243, 12584, 4676, 1363]\n",
      "1071.0\n",
      "2.15270644131\n"
     ]
    }
   ],
   "source": [
    "# to predict? first play with main loop\n",
    "id = nTest\n",
    "[usr, art] = test_data[id]\n",
    "print usr, art\n",
    "# find user index\n",
    "i = prof_idx[usr]\n",
    "# find assigned cluster\n",
    "k = predKs[i]\n",
    "# construct list of plays of artist 'art' in cluster 'K'\n",
    "playslist = []\n",
    "for u in k_ids: # for all users in cluster k\n",
    "    # try for KeyError exception if no data\n",
    "    try:\n",
    "        playslist.append(train_data[u][art]) # see if this cluster user has listened to artist\n",
    "    except KeyError: # if not\n",
    "        # playslist.append(0) # can add zero?\n",
    "        pass # or just pass?\n",
    "out = np.median(playslist) # take median plays for that artist within this cluster\n",
    "print playslist\n",
    "print out\n",
    "print float(np.sum(playslist)) / clusterMem[k].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4154804\n"
     ]
    }
   ],
   "source": [
    "# seems to do reasonably well, and not not take forever\n",
    "# try full prediciton set?\n",
    "\n",
    "pred_fin = np.zeros([nTest,1])\n",
    "pred_errs = np.zeros([nTest,1]) # also store errors if validating\n",
    "\n",
    "for itmp in range(nTest): # for all test combos\n",
    "    idx = itmp + 1 # count from 1 to nTest, rather than 0 to 1-nTest\n",
    "    \n",
    "    # [usr, art] = test_data[art] # retrieve user-artist pairs for testing\n",
    "    \n",
    "    # if validating? retrieve extra value which has true number of plays\n",
    "    [usr, art, tru] = test_data[art]\n",
    "    \n",
    "    # find user index\n",
    "    i = prof_idx[usr]\n",
    "    # find assigned cluster\n",
    "    k = predKs[i]\n",
    "    # construct list of plays of artist 'art' in cluster 'K'\n",
    "    playslist = []\n",
    "    for u in k_ids: # for all users in cluster k\n",
    "        # try for KeyError exception if no data\n",
    "        try:\n",
    "            playslist.append(train_data[u][art]) # see if this cluster user has listened to artist\n",
    "        except KeyError: # if not\n",
    "            # playslist.append(0) # can add zero?\n",
    "            pass # or just pass?\n",
    "    out = np.median(playslist) # take median plays for that artist within this cluster\n",
    "    pred_fin[itmp] = out # populate predicitons\n",
    "    pred_errs[itmp]= np.absolute(out - true) # take absolute value of error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# error metric? average absolute error\n",
    "MAE = np.mean(pred_errs)\n",
    "print MAE # target: 137 for user medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233286L, 10L)\n"
     ]
    }
   ],
   "source": [
    "# convert predicted K's to cluster means\n",
    "nPred = predKs.shape[0]\n",
    "pred_means = np.ndarray([nPred,nPCs]) # create data structure\n",
    "\n",
    "# populate\n",
    "for p in range(nPred):\n",
    "    pred_means[p] = mus[predKs[p]] # with assigned cluster mean\n",
    "print pred_means.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-21b9605048ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# rotate these pca-space means back to (standardized) artist space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mVred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnPCs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_means\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mpred_scaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# rotate these pca-space means back to (standardized) artist space\n",
    "Vred = V.T[:nPCs].T\n",
    "pred_scaled = np.dot(Vred,pred_means.T).T\n",
    "\n",
    "print pred_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# unstandardize\n",
    "pred_fin = std_scale.inverse_transform(pred_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.534199595\n"
     ]
    }
   ],
   "source": [
    "# first, if validation set: test error?\n",
    "truvals = data_mat[:nValid]\n",
    "\n",
    "MAE = np.sum(np.absolute(pred_fin - truvals))/pred_fin.size\n",
    "print MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233286L, 2000L)\n"
     ]
    }
   ],
   "source": [
    "print pred_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>user</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>306e19cce2522fa2d39ff5dfc870992100ec22d2</td>\n",
       "      <td>4ac4e32b-bd18-402e-adad-ae00e72f8d85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9450d351278df4938bdea4ed86aec940a4e927ac</td>\n",
       "      <td>1f574ab1-a46d-4586-9331-f0ded23e0411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>801909d6955f59033c88595d3d7f8a6a5dcd53cc</td>\n",
       "      <td>3eb72791-6322-466b-87d3-24d74901eb2d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>e3ed47445c127fbeff47fb58f6bbf2f3b4535d82</td>\n",
       "      <td>61604b45-8a91-4e33-a1b6-45d7b1fec4e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a73f46652103f3a5f7429159310f6928f79644aa</td>\n",
       "      <td>5dfdca28-9ddc-4853-933c-8bc97d87beec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                      user  \\\n",
       "0   1  306e19cce2522fa2d39ff5dfc870992100ec22d2   \n",
       "1   2  9450d351278df4938bdea4ed86aec940a4e927ac   \n",
       "2   3  801909d6955f59033c88595d3d7f8a6a5dcd53cc   \n",
       "3   4  e3ed47445c127fbeff47fb58f6bbf2f3b4535d82   \n",
       "4   5  a73f46652103f3a5f7429159310f6928f79644aa   \n",
       "\n",
       "                                 artist  \n",
       "0  4ac4e32b-bd18-402e-adad-ae00e72f8d85  \n",
       "1  1f574ab1-a46d-4586-9331-f0ded23e0411  \n",
       "2  3eb72791-6322-466b-87d3-24d74901eb2d  \n",
       "3  61604b45-8a91-4e33-a1b6-45d7b1fec4e5  \n",
       "4  5dfdca28-9ddc-4853-933c-8bc97d87beec  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore test data to see if this is doing the right thing\n",
    "test_df = pd.read_csv(test_file)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306e19cce2522fa2d39ff5dfc870992100ec22d2 4ac4e32b-bd18-402e-adad-ae00e72f8d85\n",
      "306e19cce2522fa2d39ff5dfc870992100ec22d2\n",
      "4ac4e32b-bd18-402e-adad-ae00e72f8d85\n",
      "0.0\n",
      "128.890206284\n"
     ]
    }
   ],
   "source": [
    "test_vals = test_df.values\n",
    "a = test_vals[0][1]\n",
    "b = test_vals[0][2]\n",
    "\n",
    "print a, b\n",
    "i = prof_idx[a]\n",
    "print all_ids[i]\n",
    "j = art_idx[b]\n",
    "print all_arts[j]\n",
    "print data_mat[i][j]\n",
    "print pred_fin[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.890206284\n"
     ]
    }
   ],
   "source": [
    "print pred_fin[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soln_file = 'Kmeans_Preds.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now: use to populate predicted values\n",
    "# Write out test solutions.\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "            \n",
    "            # find corresponding index\n",
    "            i = prof_idx[user] # use dictionary to find i value\n",
    "            j = art_idx[artist] # use other dictionary to find j\n",
    "\n",
    "            soln_csv.writerow([id, pred_fin[i][j]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the global median and per-user median.\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "for user, user_data in train_data.iteritems():\n",
    "    user_plays = []\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "\n",
    "    user_medians[user] = np.median(np.array(user_plays))\n",
    "global_median = np.median(np.array(plays_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soln_file = 'median_test.csv'\n",
    "\n",
    "# Write out test solutions.\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "\n",
    "            if user in user_medians:\n",
    "                soln_csv.writerow([id, user_medians[user]])\n",
    "            else:\n",
    "                print \"User\", id, \"not in training data.\"\n",
    "                soln_csv.writerow([id, global_median])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
